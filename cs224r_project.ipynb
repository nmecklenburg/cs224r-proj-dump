{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","private_outputs":true,"collapsed_sections":["KE6al1zsbLpe"],"authorship_tag":"ABX9TyNiWABVvX30UNEBC8LU+gMf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -U 'bitsandbytes<0.46.0' --quiet\n","!pip install -U flash-attn --no-build-isolation --quiet\n","!pip install 'git+https://github.com/nmecklenburg/transformers.git@nmeck/proj-changes#egg=transformers[torch]' --quiet\n","!pip install -U 'vllm<0.9.0' --quiet\n","# !pip install -U 'trl<0.18.0' --quiet\n","!pip install 'git+https://github.com/nmecklenburg/trl.git@nmeck/proj-changes#egg=trl' --quiet\n","!pip install -U 'tensorboard<2.19' --quiet"],"metadata":{"id":"hQqvIdV_c_le"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import concatenate_datasets, load_dataset, Dataset\n","from itertools import islice\n","from peft import LoraConfig, PeftModel, get_peft_model\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from trl import (\n","    GRPOConfig,\n","    GRPOTrainer,\n","    SFTConfig,\n","    SFTTrainer,\n","    get_peft_config,\n",")\n","\n","import bitsandbytes\n","import re\n","import shutil\n","import torch"],"metadata":{"id":"erpaomSegAP9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"DaoXnBdTMNA-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Countdown Dataset Synthesis"],"metadata":{"id":"KE6al1zsbLpe"}},{"cell_type":"code","source":["import operator\n","import random\n","\n","from sympy import sympify\n","\n","result = sympify(\"1 + 4 * 7 + 4 / 2\")\n","print(result)"],"metadata":{"id":"QqExvvuPb8AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MAX_NUMBER = 100\n","\n","def get_factors(n):\n","  factors = []\n","  divisor = int(n ** 0.5) + 1\n","  while divisor > 1:\n","    if n % divisor == 0:\n","      factors.append(divisor)\n","      factors.append(n // divisor)\n","    divisor -= 1\n","  return list(set(factors))\n","\n","def is_prime(n):\n","  if n <= 3:\n","    return True\n","\n","  # Check if n is composite\n","  prime = True\n","  for i in range(2, int(n**0.5) + 1):\n","    if n % i == 0:\n","      prime = False\n","      break\n","\n","  return prime\n","\n","def get_random_divisor(n):\n","  factors = get_factors(n)\n","  return random.choice(factors)\n","\n","def get_random_number(op=None, last_num=None):\n","  if op == \"/\":\n","    assert last_num is not None\n","    return get_random_divisor(last_num)\n","  return random.randint(1, MAX_NUMBER)\n","\n","def get_composite_number():\n","  num = random.randint(1, MAX_NUMBER)\n","  while is_prime(num):\n","    num = random.randint(1, MAX_NUMBER)\n","  return num\n","\n","sym_to_op = {\n","    \"+\": operator.add,\n","    \"-\": operator.call,\n","    \"*\": operator.mul,\n","    \"/\": operator.floordiv\n","}"],"metadata":{"id":"hBVmrUDPdSTE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NUM_EXAMPLES_TO_GENERATE = 10000\n","MIN_OPERATORS, MAX_OPERATORS = 2, 3\n","VALID_OPERATORS = [\"+\", \"-\", \"*\", \"/\"]\n","\n","bank = [] # (result, factors, equation)\n","\n","while len(bank) < NUM_EXAMPLES_TO_GENERATE:\n","  formula = [get_composite_number()]\n","  num_operators = random.randint(MIN_OPERATORS, MAX_OPERATORS)\n","\n","  for _ in range(num_operators):\n","    op = random.choice(VALID_OPERATORS)\n","    if is_prime(formula[-1]) and op == \"/\":\n","      # Only divide composite numbers.\n","      break\n","    else:\n","      num = get_random_number(op=op, last_num=formula[-1])\n","    formula.extend([op, num])\n","\n","  if len(formula) < (2 * num_operators + 1):\n","    continue\n","\n","  formula_expr = ' '.join([str(f) for f in formula])\n","  result = sympify(formula_expr)\n","  if result > 0 and result < 2000 and str(result).isnumeric():\n","    bank.append((result, sorted([f for f in formula if isinstance(f, int)], key=lambda _: random.random()), formula_expr))"],"metadata":{"id":"NqUngTtobI54"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bank[0]"],"metadata":{"id":"ufSjnVJvub3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QZiYcuPGFVVt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Datasets"],"metadata":{"id":"xpyrDAS6FVt4"}},{"cell_type":"code","source":["PRETRAINED_MODEL_NAME = \"Qwen/Qwen2-0.5B-Instruct\"\n","# PRETRAINED_MODEL_NAME = \"Microsoft/Phi-3.5-mini-instruct\"\n","# PRETRAINED_MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\""],"metadata":{"id":"DwvLIsoCNDYU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========= OLD FORMAT =========\n","# countdown_prompt_template = (\n","#     \"You will be given a math puzzle with a set of NUMBERS that can be combined with ('+', '-', '*', '/') to form some target RESULT.\"\n","#     \"Think step by step and find the equation that satisfies the problem. Enclose your final formula in <answer></answer> tags.\"\n","#     \"Example: [1, 2, 4] with a target of 2 -> <answer>1 * 4 - 2</answer>\\n\\nNUMBERS: {nums}\\nRESULT: {result}\\n\"\n","# )\n","\n","# def create_countdown_prompt_column(example):\n","#   example[\"prompt\"] = countdown_prompt_template.format(nums=example['nums'], result=example['target'])\n","#   return example"],"metadata":{"id":"3kp4odSYNKd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["COUNTDOWN_PROMPT = (\n","    \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\\n\"\n","    \"User: Using the numbers {nums}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\\n\"\n","    \"Assistant: Let me solve this step by step.\\n<think>\"\n",")\n","\n","\n","def reformat_o4m_synth_row(example):\n","  answer_start_idx = example['cot'].index(\"<answer>\")\n","  example[\"completion\"] = f\"<think>{example['cot'][:answer_start_idx]}</think>{example['cot'][answer_start_idx:]}\"\n","  example[\"prompt\"] = COUNTDOWN_PROMPT.format(nums=example['numbers'], target=example['target'])\n","  del example['numbers'], example['target'], example['cot'], example['expression']\n","  return example\n","\n","\n","def prompt_to_entry(text):\n","  m = re.match(r\"[\\s\\S]+Using the numbers \\[(.*)\\], create an equation that equals (\\d+)\", text)\n","  nums, target = m.group(1), m.group(2)\n","  entry = ((tuple(sorted(int(i) for i in nums.split(', ')))), int(target))\n","  return entry\n","\n","def reformat_rft(example):\n","  example[\"prompt\"] = COUNTDOWN_PROMPT.format(nums=example['nums'], target=example['target'])\n","  return example\n","\n","def reformat_val(example):\n","  example[\"prompt\"] += \"\\n<think>\"\n","  return example"],"metadata":{"id":"8KWbhUJkct-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATASET_TYPE = \"COUNTDOWN\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n","tokenizer.padding_side = 'left'\n","\n","\n","if DATASET_TYPE == \"MATH\":\n","  # We may not use all 50k, but if we increase/decrease the dataset during exp.,\n","  # give some wiggle room so we can be consistent with the validation set.\n","  N_TOTAL = 50_000\n","  N_SFT_TRAIN_EXAMPLES = 10_000\n","  N_RFT_TRAIN_EXAMPLES = 500\n","  assert(N_SFT_TRAIN_EXAMPLES + N_RFT_TRAIN_EXAMPLES < N_TOTAL)\n","  N_VALID_EXAMPLES = 1_000\n","\n","  # https://huggingface.co/datasets/PrimeIntellect/verifiable-math-problems/viewer/default/train?views%5B%5D=train&row=4\n","  dataset_stream = load_dataset(\"PrimeIntellect/verifiable-math-problems\", split=\"train\", streaming=True)\n","  dataset_slice = list(islice(dataset_stream, N_TOTAL + N_VALID_EXAMPLES))\n","  sft_train_dataset = Dataset.from_list(dataset_slice[:N_SFT_TRAIN_EXAMPLES])\n","  rft_train_dataset = Dataset.from_list(dataset_slice[N_SFT_TRAIN_EXAMPLES:N_SFT_TRAIN_EXAMPLES + N_RFT_TRAIN_EXAMPLES])\n","  valid_dataset = Dataset.from_list(dataset_slice[N_TOTAL:N_TOTAL + N_VALID_EXAMPLES])\n","\n","  avg_toks_per_example = 0\n","  for example in sft_train_dataset:\n","    avg_toks_per_example += len(tokenizer(example['prompt'], add_special_tokens=True)['input_ids']) + len(tokenizer(example['gold_standard_solution'], add_special_tokens=True)['input_ids'])\n","  avg_toks_per_example = int(avg_toks_per_example / N_SFT_TRAIN_EXAMPLES)\n","\n","  sft_train_dataset = sft_train_dataset.rename_column(\"gold_standard_solution\", \"completion\")\n","  sft_train_dataset = sft_train_dataset.remove_columns([col for col in sft_train_dataset.column_names if col not in {\"prompt\", \"completion\"}])\n","\n","elif DATASET_TYPE == \"COUNTDOWN\":\n","  # === COUNTDOWN V1 ===\n","  # sft_train_dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/cs224r/data/synth_countdown_sft_10k.jsonl\", split=\"train\")\\\n","  #     .rename_columns({\"numbers\": \"nums\", \"cot\": \"completion\"})\\\n","  #     .map(create_countdown_prompt_column)\\\n","  #     .remove_columns([\"target\", \"nums\"])\n","  # rft_train_dataset = load_dataset(\"predibase/countdown\", split=f\"train[:{N_RFT_TRAIN_EXAMPLES}]\")\\\n","  #   .map(create_countdown_prompt_column)\n","  # valid_dataset = load_dataset(\"predibase/countdown\", split=f\"train[{N_RFT_TRAIN_EXAMPLES}:]\")\\\n","  #   .map(create_countdown_prompt_column)\n","  # test_dataset = load_dataset(\"predibase/countdown\", split=\"test\")\\\n","  #   .map(create_countdown_prompt_column)\n","\n","  synth_dataset = load_dataset(\n","      \"json\",\n","      data_files=\"/content/drive/MyDrive/cs224r/data/synth_countdown_sft_10k.jsonl\",\n","      split=\"train\"\n","  ).map(reformat_o4m_synth_row)\n","  synth_train_dataset = synth_dataset.select(range(9700))\n","  synth_valid_dataset = synth_dataset.select(range(9700, 10000))  # val set 200 -> 500\n","\n","  predet_train_dataset = load_dataset(\"Asap7772/cog_behav_all_strategies\", split=\"train\")\\\n","        .rename_columns({\"query\": \"prompt\"})\n","  sft_train_dataset = concatenate_datasets([synth_train_dataset, predet_train_dataset])\n","\n","  rft_train_dataset = load_dataset(\"Jiayi-Pan/Countdown-Tasks-3to4\", split=\"train[:20000]\")\\\n","        .map(reformat_rft)\n","\n","  valid_dataset = concatenate_datasets([\n","      load_dataset(\"Asap7772/cog_behav_all_strategies\", split=\"test\")\\\n","        .rename_columns({\"query\": \"prompt\"})\\\n","        .map(reformat_val),\n","      synth_valid_dataset\n","  ])\n","\n","  TARGET_BANK = set()\n","  for row in valid_dataset:\n","    TARGET_BANK.add(prompt_to_entry(row[\"prompt\"]))\n","\n","  def remove_data_leaks(row):\n","    entry = prompt_to_entry(row['prompt'])\n","    return entry not in TARGET_BANK\n","\n","  sft_train_dataset = sft_train_dataset.filter(remove_data_leaks)"],"metadata":{"id":"fwVkid2__Sm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(sft_train_dataset)\n","print(rft_train_dataset)\n","print(valid_dataset)"],"metadata":{"id":"boXOoTwieqBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def round_up_to_power_of_2(n):\n","#     # -- ChatGPT --\n","#     if n < 1:\n","#         return 1\n","#     # If n is already a power of two, return n\n","#     if (n & (n - 1)) == 0:\n","#         return n\n","#     power = 1\n","#     while power < n:\n","#         power <<= 1  # multiply power by 2\n","#     return power\n","\n","# sequence_length = min(round_up_to_power_of_2(avg_toks_per_example), 2048)"],"metadata":{"id":"xOzO9u94F-b2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sequence_length"],"metadata":{"id":"3LowWAfRGMGV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = AutoModelForCausalLM.from_pretrained(\n","#     PRETRAINED_MODEL_NAME,\n","#     # quantization_config=bnb_config,\n","#     torch_dtype=\"auto\",\n","#     device_map=\"auto\",\n","#     attn_implementation=\"flash_attention_2\"\n","# )\n","\n","# sft_training_args = SFTConfig(\n","#   # Memory Parameters\n","#   max_length=1024,\n","#   bf16=True,\n","#   gradient_checkpointing=True,\n","#   num_train_epochs=10,\n","#   save_strategy=\"epoch\",\n","#   # Throughput\n","#   packing=True,\n","#   # Logging\n","#   logging_steps=20,\n","#   output_dir=\"./sft_checkpoints\",\n","#   report_to=\"none\",\n","# )\n","\n","# sft_trainer = SFTTrainer(\n","#     model,\n","#     train_dataset=sft_train_dataset,\n","#     args=sft_training_args\n","# )\n","# sft_trainer.train()"],"metadata":{"id":"QsZUvzHe5DmC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# for ckpt in os.listdir(\"/content/sft_checkpoints/\"):\n","#   try:\n","#     step = int(ckpt.split('-')[-1])\n","#     dst = f\"/content/drive/MyDrive/cs224r/sft/countdown-joint/qwen2-0.5b-checkpoint-{step}\"\n","#     if not os.path.exists(dst):\n","#       shutil.copytree(f\"/content/sft_checkpoints/checkpoint-{step}\", dst)\n","#   except:\n","#     continue"],"metadata":{"id":"NHw_GoFNneN9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Automatically disconnect and shut down the Colab runtime\n","# import os\n","# from google.colab import runtime\n","\n","# # Option 1: Using the Colab `runtime` module (cleanest method)\n","# runtime.unassign()\n","\n","# # Option 2: Force shutdown (in case unassign doesn't work)\n","# os._exit(0)"],"metadata":{"id":"JUphIOMNryk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# max_step = -1\n","# max_ckpt = None\n","# for ckpt in os.listdir(\"/content/sft_checkpoints/\"):\n","#   try:\n","#     step = int(ckpt.split('-')[-1])\n","#     if step > max_step:\n","#       max_step = step\n","#       max_ckpt = ckpt\n","#   except:\n","#     continue\n","\n","# if max_ckpt is not None:\n","#   dst = f\"/content/drive/MyDrive/cs224r/sft/countdown/qwen2-0.5b-checkpoint-{max_step}\"\n","#   if not os.path.exists(dst):\n","#     shutil.copytree(f\"/content/sft_checkpoints/{max_ckpt}\", dst)"],"metadata":{"id":"5YB3lb9eNJiM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Automatically disconnect and shut down the Colab runtime\n","# import os\n","# from google.colab import runtime\n","\n","# # Option 1: Using the Colab `runtime` module (cleanest method)\n","# runtime.unassign()\n","\n","# # Option 2: Force shutdown (in case unassign doesn't work)\n","# os._exit(0)"],"metadata":{"id":"eekU4QFnGpPd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import re\n","import time\n","\n","from sympy import sympify, SympifyError\n","\n","os.environ[\"PROFILE_REWARDS\"] = \"false\"\n","\n","def reward_accuracy(prompts, completions, verification_info, **kwargs):\n","  \"\"\"\n","  Reward via string-equals-check on boxed answer vs ground truth. Vulnerable to\n","  edge cases where model outputs multiple boxed answers (we would get the first)\n","  or if the boxed answer is not at the end of the completion and other\n","  curly brackets come later on due regex greedy match.\n","  \"\"\"\n","  start_time = time.time()\n","  rewards = []\n","  for idx, (completion, verification_info) in enumerate(zip(completions, verification_info)):\n","    completion_match = re.search(r'\\\\boxed\\{(.*)\\}', completion)\n","    reference_match = re.match(r\".*ground_truth':[\\s]*'(.*)'}\", verification_info)\n","    if completion_match is None or reference_match is None:\n","      rewards.append(0)\n","    else:\n","      candidate, reference = completion_match.group(1).strip(), reference_match.group(1).strip()\n","      is_correct = candidate == reference\n","      rewards.append(int(is_correct) * 1.0)\n","  if os.getenv(\"PROFILE_REWARDS\", '').lower() == \"true\":\n","    print(f\"Accuracy duration: {time.time() - start_time}\")\n","  return rewards\n","\n","\n","def len_penalty(completions, **kwargs):\n","    \"\"\"Reward function that assigns higher scores to longer completions (in terms of token count).\"\"\"\n","    # Documentation bug:\n","    # TRL passes in `completion_ids` - https://github.com/huggingface/trl/blob/29401e790efd232a1bb14a247a7875fc789f0a7b/trl/trainer/grpo_trainer.py#L1167\n","    # But GRPO docs suggest `completions_ids` - https://huggingface.co/docs/trl/main/en/grpo_trainer#using-a-custom-reward-function\n","    start_time = time.time()\n","    # prev: 100000\n","    rewards = [-float(len(completion)) / 1500 for completion in completions]\n","    if os.getenv(\"PROFILE_REWARDS\", '').lower() == \"true\":\n","      print(f\"Length penalty duration: {time.time() - start_time}\")\n","    return rewards\n","\n","\n","def format_reward(completions, **kwargs):\n","  rewards = []\n","  for completion in completions:\n","    completion = \"<think>\" + completion\n","    opened_think = completion.count(\"<think>\") == 1\n","    closed_think = completion.count(\"</think>\") == 1\n","    opened_answer = completion.count(\"<answer>\") == 1\n","    closed_answer = completion.count(\"</answer>\") == 1\n","    if not (opened_think and closed_think and opened_answer and closed_answer):\n","      rewards.append(0.0)\n","    else:\n","      rewards.append(\n","          1.0 if re.match(\n","              r\"[\\s\\S]*<think>[\\s\\S]*</think>[\\s\\S]*<answer>[\\s\\S]*</answer>[\\s\\S]*\",\n","              completion\n","              ) is not None else 0.0\n","          )\n","  return rewards\n","\n","\n","def formula_match(prompts, completions, target, nums, **kwargs):\n","  rewards = []\n","  for prompt, completion, target, num_list in zip(prompts, completions, target, nums):\n","    candidate_nums = [int(i) for i in re.findall(r'\\d+', completion)]\n","    answer = re.match(r\"[\\s\\S]*<answer>(.*?)</answer>.*\", completion)\n","    if set(candidate_nums) != set(num_list) or answer is None:\n","      rewards.append(0)\n","    else:\n","      try:\n","        candidate_target = sympify(answer.group(1))\n","        rewards.append(int(candidate_target == target))\n","      except (SympifyError, TypeError):\n","        rewards.append(0)\n","  return rewards\n","\n","\n","def formula_match_v2(prompts, completions, **kwargs):\n","  rewards = []\n","  for prompt, completion in zip(prompts, completions):\n","    target = int(\n","        re.match(r\"[\\s\\S]*create an equation that equals (\\d+).*\", prompt).group(1)\n","    )\n","    ref_nums, _ = prompt_to_entry(prompt)\n","    answer = re.match(r\"[\\s\\S]*<answer>(.*?)</answer>.*\", completion)\n","\n","    try:\n","      candidate_target = sympify(answer.group(1))\n","      rewards.append(int(candidate_target == target))\n","    except (SympifyError, TypeError, AttributeError):\n","      rewards.append(0)\n","  return rewards\n","\n","\n","def formula_match_v3(prompts, completions, **kwargs):\n","  rewards = []\n","  for prompt, completion in zip(prompts, completions):\n","    target = int(\n","        re.match(r\"[\\s\\S]*create an equation that equals (\\d+).*\", prompt).group(1)\n","    )\n","    ref_nums, _ = prompt_to_entry(prompt)\n","    answer = re.match(r\"[\\s\\S]*<answer>(.*?)</answer>.*\", completion)\n","\n","    try:\n","      # Did we use duplicate numbers when we shouldn't have,\n","      # or hallucinate numbers to make the numbers work?\n","      cand_nums = [int(i) for i in re.findall(r\"\\d+\", answer.group(1))]\n","      ref_counts = {i: ref_nums.count(i) for i in ref_nums}\n","      cand_counts = {i: cand_nums.count(i) for i in cand_nums}\n","\n","      if any([cand_counts[i] > ref_counts.get(i, 0) for i in cand_counts]):\n","        rewards.append(0.0)\n","      else:\n","        candidate_target = sympify(answer.group(1))\n","        rewards.append(float(candidate_target == target))\n","    except (SympifyError, TypeError, AttributeError):\n","      rewards.append(0.0)\n","  return rewards"],"metadata":{"id":"Ej_N8RtLeslq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_dataset[0]"],"metadata":{"id":"6NDDO6_VZxnr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Math\n","prompts = [\"Do some math, eh?\", \"What is math?\"]\n","completions = [\"\\\\boxed{x = 3}\", \"\\\\boxed{712}\"]\n","reference_answers = [\"{'ground_truth': 'x = 3'}\", \"{'ground_truth': '711'}\"]\n","completion_ids = [[6303, 13], [304, 279, 12884, 13]]\n","print(reward_accuracy(prompts=prompts, completions=completions, completion_ids=completion_ids, verification_info=reference_answers))\n","print(len_penalty(prompts=prompts, completions=completions, completion_ids=completion_ids, verification_info=reference_answers))"],"metadata":{"id":"yAjrDv4zg9b9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Countdown\n","completions = [\"Let me think about that ... </think><answer>12 + 40 / 10</answer> Was that okay?\",\n","               \"Some stuff <answer>3 + 4 + 5</answer> How'd I do?\",\n","               \"This one on the other hand has me stumped\"]\n","targets = [16, 13, 4]\n","nums = [[12, 40, 10], [3, 4, 5], [20, 50, 63]]\n","print(format_reward(completions))\n","print(formula_match([\"p1\", \"p2\", \"p3\"], completions, targets, nums))"],"metadata":{"id":"gqzvKf3sdmb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comps = [\n","    \"Human-readable solution:\\n1. Since 57 is our target and we have two 76s, we need to find a way to get one of them into the same form as 57\\n2. Looking at 76, if we divide 76 by something, we might get close to 57\\n3. Let's try dividing 76 by 57:\\n   - 76/57 ≈ 1.29\\n4. Another approach: \\n   - 76-57 = 19\\n   - 76*57 would be too large\\n5. Let's try another sequence:\\n   - 76+57 = 133\\n   - 133/76 ≈ 1.80\\n6. New approach:\\n   - 76-76 = 0\\n   - 57+0 = 57\\n7. Found it! We can do:\\n   - First subtract 76 from 76: 76-76 = 0\\n   - Then add that result to 57: 0+57 = 57\\n</think>\\n<answer>(76-76)+57</answer>\",\n","    \"<think>some chain of thought</think><answer>1 + 2 + 3</answer>\",   # wrong answer, wrong nums\n","    \"<think>some chain of thought</think><answer>28 * 2 + 1</answer>\",  # right answer, wrong nums\n","    \"<think>some chain of thought</think><answer>57 / 76 + 76</answer>\", # wrong answer, right nums\n","    \"<think>some chain of thought</think><answer>57 + 76 - 76 + 76 - 76</answer>\", # right answer, right nums but duplicates\n","    ]\n","prompts = [\n","    \"'A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\\nUser: Using the numbers [57, 76, 76], create an equation that equals 57. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\\nAssistant: Let me solve this step by step.\",\n","    \"'A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\\nUser: Using the numbers [57, 76, 76], create an equation that equals 57. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\\nAssistant: Let me solve this step by step.\",\n","    \"'A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\\nUser: Using the numbers [57, 76, 76], create an equation that equals 57. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\\nAssistant: Let me solve this step by step.\",\n","    \"'A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\\nUser: Using the numbers [57, 76, 76], create an equation that equals 57. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\\nAssistant: Let me solve this step by step.\",\n","    \"'A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\\nUser: Using the numbers [57, 76, 76], create an equation that equals 57. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\\nAssistant: Let me solve this step by step.\",\n","]\n","print(formula_match_v3(prompts, comps))"],"metadata":{"id":"fa07luTrS3ZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if DATASET_TYPE == \"MATH\":\n","  avg_prompt_toks, avg_completion_toks = 0, 0\n","  for example in rft_train_dataset:\n","    avg_prompt_toks += len(tokenizer(example['prompt'], add_special_tokens=True)['input_ids'])\n","    avg_completion_toks += len(tokenizer(example['gold_standard_solution'], add_special_tokens=True)['input_ids'])\n","  avg_prompt_toks = int(avg_prompt_toks / N_RFT_TRAIN_EXAMPLES)\n","  avg_completion_toks = int(avg_completion_toks / N_RFT_TRAIN_EXAMPLES)\n","  print(f\"{avg_prompt_toks=}\")\n","  print(f\"{avg_completion_toks=}\")"],"metadata":{"id":"fpBovYkjQIOh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb\n","wandb.init(mode=\"disabled\")  # since for some reason report_to='none' is not enough for GRPO"],"metadata":{"id":"G9SZDYOeRxSK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","if not os.path.exists(\"/content/local-sft-checkpoint\"):\n","  shutil.copytree(\"/content/drive/MyDrive/cs224r/sft/countdown-joint/qwen2-0.5b-checkpoint-11050\", \"/content/local-sft-checkpoint\")\n","    # shutil.copytree(\"/content/drive/MyDrive/cs224r/sft/countdown-joint/qwen2-0.5b-checkpoint-1105\", \"/content/local-sft-checkpoint\")"],"metadata":{"id":"gfP3ic6IpA7H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### <-- Moved this into custom trl fork; no longer necessary in colab -->\n","\n","# ### FIX ANNOYING TRL <-> TRANSFORMERS BUGS ###\n","# # Fix bug in trl <-> transformers\n","# from transformers.trainer_utils import seed_worker\n","# from torch.utils.data import DataLoader\n","# from transformers.utils import is_datasets_available\n","# from transformers import TrainerCallback\n","\n","# import json\n","\n","\n","# class LogCallback(TrainerCallback):\n","#     def __init__(self):\n","#       self.fpath = \"/content/logs/latest_metrics.txt\"\n","#       os.makedirs(os.path.dirname(self.fpath), exist_ok=True)\n","\n","#     def on_log(self, args, state, control, logs=None, **kwargs):\n","#       with open(self.fpath, \"a\") as f:\n","#         if logs:\n","#           f.write(json.dumps(logs) + '\\n')\n","\n","\n","# class HappyGRPOTrainer(GRPOTrainer):\n","#     def get_train_dataloader(self):\n","#         if self.train_dataset is None:\n","#             raise ValueError(\"Trainer: training requires a train_dataset.\")\n","\n","#         train_dataset = self.train_dataset\n","#         data_collator = self.data_collator\n","#         if is_datasets_available() and isinstance(train_dataset, Dataset):\n","#             train_dataset = self._remove_unused_columns(train_dataset, description=\"training\")\n","#         else:\n","#             data_collator = self._get_collator_with_removed_columns(data_collator, description=\"training\")\n","\n","#         dataloader_params = {\n","#             \"batch_size\": self._train_batch_size * self.args.gradient_accumulation_steps,  # < this is the change\n","#             \"collate_fn\": data_collator,\n","#             \"num_workers\": self.args.dataloader_num_workers,\n","#             \"pin_memory\": self.args.dataloader_pin_memory,\n","#             \"persistent_workers\": self.args.dataloader_persistent_workers,\n","#         }\n","\n","#         if not isinstance(train_dataset, torch.utils.data.IterableDataset):\n","#             dataloader_params[\"sampler\"] = self._get_train_sampler()\n","#             dataloader_params[\"drop_last\"] = self.args.dataloader_drop_last\n","#             dataloader_params[\"worker_init_fn\"] = \\\n","#               partial(seed_worker,\n","#                       num_workers=rft_training_args.dataloader_num_workers,\n","#                       rank=rft_training_args.process_index)\n","#             dataloader_params[\"prefetch_factor\"] = self.args.dataloader_prefetch_factor\n","\n","#         return self.accelerator.prepare(DataLoader(train_dataset, **dataloader_params))\n","\n","# metric_file_logger = LogCallback()"],"metadata":{"id":"gQMv79EZ4yoX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Qwen2.5 0.5B params:\n","\n","rft_training_args = GRPOConfig(\n","    # Memory\n","    bf16=True,\n","    per_device_train_batch_size=24,\n","    per_device_eval_batch_size=0,\n","    num_generations=4,\n","    gradient_checkpointing=True,\n","    max_prompt_length=256,\n","    max_completion_length=512,\n","    gradient_accumulation_steps=4,\n","    # Throughput\n","    use_vllm=False,\n","    # vllm_mode=\"colocate\",  # single-gpu setting\n","    num_train_epochs = 1, # Set to 1 for a full training run\n","    max_steps = -1,\n","    dataloader_num_workers=8,\n","    dataloader_prefetch_factor=2,\n","    dataloader_pin_memory=True,\n","    dataloader_persistent_workers=True,\n","    # Logging\n","    output_dir=\"./rft-checkpoints\",\n","    # save_strategy=\"epoch\",\n","    # save_total_limit=2,\n","    report_to=\"none\",\n",")\n","\"\"\""],"metadata":{"id":"_8yo-Sd0-MOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"wnQSgfRtNitO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir ./logs"],"metadata":{"id":"R9K49l7cPIzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","with open(\"/content/drive/MyDrive/cs224r/rft/countdown-joint/batches_to_exclude_bs16.json\", \"r\") as f:\n","  batches_to_exclude = {i for i, _ in json.load(f)}"],"metadata":{"id":"S-Guw3ZoH4VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""],"metadata":{"id":"tU03qtEeymai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# {'top_k': 20, 'top_p': 0.8, 'repetition_penalty': 1.1, 'bos_token_id': 151643}\n","\n","RUN_NAME = \"V31\"\n","\n","peft_config = LoraConfig(\n","  r=8,\n","  lora_alpha=32,\n","  lora_dropout=0.1,\n","  bias=\"none\",\n","  task_type=\"CAUSAL_LM\",\n",")\n","\n","rft_training_args = GRPOConfig(\n","    # Memory\n","    bf16=True,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=0,\n","    gradient_checkpointing=True,\n","    gradient_checkpointing_kwargs={\"use_reentrant\": False},  # it sets use_cache=False anyways, but to be explicit...\n","    gradient_accumulation_steps=1,\n","    # Throughput\n","    use_vllm=False,\n","    # vllm_mode=\"colocate\",  # single-gpu setting\n","    dataloader_num_workers=8,\n","    dataloader_prefetch_factor=2,\n","    dataloader_pin_memory=True,\n","    dataloader_persistent_workers=True,\n","    # Logging\n","    output_dir=\"./rft-checkpoints\",\n","    logging_dir=f\"./logs/{RUN_NAME}\",\n","    save_strategy=\"steps\",\n","    save_steps=25,\n","    run_name=RUN_NAME,\n","    # save_total_limit=2,\n","    logging_steps=1,\n","    report_to=[\"tensorboard\"],\n","    # Training\n","    reward_weights=[1.0, 0.1],\n","    # scale_rewards=False,\n","    # loss_type=\"dr_grpo\",\n","    beta=0.001,\n","    num_train_epochs = 1, # Set to 1 for a full training run\n","    learning_rate=1e-5,\n","    # lr_scheduler_type=\"cosine\",\n","    # warmup_ratio=0.03,\n","    max_steps = 400,\n","    # max_grad_norm=1.5,\n","    # epsilon_high=0.28,\n","    # Sampling\n","    num_generations=16,\n","    max_prompt_length=256,\n","    max_completion_length=1024,\n","    mask_truncated_completions=True,\n","    temperature=1.01,\n","    top_p=0.8,\n","    top_k=100,\n","    bottom_p=0.9,\n",")\n","\n","rft_trainer = GRPOTrainer(\n","    \"/content/local-sft-checkpoint\",\n","    # reward_funcs=[reward_accuracy, len_penalty],  # MATH\n","    reward_funcs=[formula_match_v3, format_reward],\n","    args=rft_training_args,\n","    train_dataset=rft_train_dataset,\n","    # callbacks=[metric_file_logger],\n","    peft_config=peft_config,\n","    optimizers=(None, None),\n","    # batches_to_exclude=batches_to_exclude,\n","    # optimizer_cls_and_kwargs=(bitsandbytes.optim.Lion8bit, {}),\n",")"],"metadata":{"id":"_g3PmVCLjZoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rft_trainer.model = torch.compile(rft_trainer.model, mode=\"default\", fullgraph=True)"],"metadata":{"id":"51QUgQH_-JVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rft_trainer.train()"],"metadata":{"id":"sUgIuNctsatu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rft_trainer.generation_config.temperature"],"metadata":{"id":"xm0njSGpbX67"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_model = rft_trainer.model.merge_and_unload()"],"metadata":{"id":"fWlUq0fbeXEf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_model.save_pretrained(\"/content/rft-merged-ckpt\")"],"metadata":{"id":"4dcBpQpOelSt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(rft_trainer.state.log_history[1])"],"metadata":{"id":"PNAt3kU_rFOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open(\"/content/rft-checkpoints/checkpoint-200/trainer_state.json\", \"r\") as f:\n","#   metrics_collection = [step for step in json.load(f)['log_history'] if \"rewards/formula_match_v3/mean\" in step]"],"metadata":{"id":"fyBMwMaA0zge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","metrics_collection = None\n","num_gen = 4  # rft_training_args.num_generations\n","\n","if DATASET_TYPE == \"MATH\":\n","  metrics_collection = metrics_collection or [step for step in rft_trainer.state.log_history if \"rewards/reward_accuracy/mean\" in step]\n","  steps = [step['step'] for step in metrics_collection]\n","  accs = [step['rewards/reward_accuracy/mean'] for step in metrics_collection]\n","  accs_errs = [step['rewards/reward_accuracy/std'] / (num_gen ** 0.5) for step in metrics_collection]\n","  lens = [step['rewards/len_penalty/mean'] for step in metrics_collection]\n","  lens_errs = [step['rewards/len_penalty/std'] / (num_gen ** 0.5) for step in metrics_collection]\n","  rewards = [step['reward'] for step in metrics_collection]\n","elif DATASET_TYPE == \"COUNTDOWN\":\n","  metrics_collection = metrics_collection or [step for step in rft_trainer.state.log_history if \"rewards/formula_match_v3/mean\" in step]\n","  steps = [step['step'] for step in metrics_collection]\n","  accs = [step['rewards/formula_match_v3/mean'] for step in metrics_collection]\n","  accs_errs = [step['rewards/formula_match_v3/std'] / (num_gen ** 0.5) for step in metrics_collection]\n","  formats = [step['rewards/format_reward/mean'] for step in metrics_collection]\n","  formats_errs = [step['rewards/format_reward/std'] / (num_gen ** 0.5) for step in metrics_collection]\n","  # lens = [step['rewards/len_penalty/mean'] for step in metrics_collection]\n","  # lens_errs = [step['rewards/len_penalty/std'] / (num_gen ** 0.5) for step in metrics_collection]\n","  rewards = [step['reward'] for step in metrics_collection]\n","  kls = [step['kl'] for step in metrics_collection]\n","  grad_norms = [step['grad_norm'] for step in metrics_collection]\n"],"metadata":{"id":"qi2Of9UIS9ot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","plt.plot(steps, accs)\n","plt.fill_between(steps, np.array(accs) - np.array(accs_errs), np.array(accs) + np.array(accs_errs), color='blue', alpha=0.3)\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"[Countdown v3] Mean Accuracy Reward (n=4)\")\n","plt.title(\"Accuracy over time for GRPO Qwen2 0.5B\")"],"metadata":{"id":"_H4bfYFdhADk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(steps, formats)\n","plt.fill_between(steps, np.array(formats) - np.array(formats_errs), np.array(formats) + np.array(formats_errs), color='blue', alpha=0.3)\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"Mean Length Penalty (n=4)\")\n","plt.title(\"Format reward over time for GRPO Qwen2 0.5B\")"],"metadata":{"id":"t-RCbSR5-pgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(steps, kls)\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"[Countdown v3] KL (n=4)\")\n","plt.title(\"KL || GRPO Qwen2 0.5B\")"],"metadata":{"id":"62C_I92HyBvf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(steps, grad_norms)\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"[Countdown v3] Gradient Norms\")\n","plt.title(\"Gradient Norms over Time || GRPO Qwen2 0.5B\")"],"metadata":{"id":"V2Y67vxFyVi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(steps, lens)\n","plt.fill_between(steps, np.array(lens) - np.array(lens_errs), np.array(lens) + np.array(lens_errs), color='blue', alpha=0.3)\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"Mean Length Penalty (n=4)\")\n","plt.title(\"Length penalty over time for GRPO Qwen2.5 1.5B\")"],"metadata":{"id":"p-nK18XZhngf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RJ3O34TI-7l8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()\n","unwrapped_model = accelerator.unwrap_model(rft_trainer.model)"],"metadata":{"id":"dNypQlh18Kow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unwrapped_model.save_pretrained(\"/content/rft-checkpoints/checkpoint-5-n=1000\")"],"metadata":{"id":"TmjgziLI8XIb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["step = 750\n","version = \"v9\"\n","dst = f\"/content/drive/MyDrive/cs224r/rft/countdown-joint/{version}/checkpoint-{step}\"\n","if not os.path.exists(dst):\n","  shutil.copytree(f\"/content/rft-checkpoints/checkpoint-{step}\", dst)"],"metadata":{"id":"ENOYsCQNTf-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# for ckpt in os.listdir(\"/content/rft-checkpoints/\"):\n","#   try:\n","#     step = int(ckpt.split('-')[-1])\n","#     dst = f\"/content/drive/MyDrive/cs224r/rft/countdown-o4m-distil/qwen2-0.5b-checkpoint-{step}\"\n","#     if not os.path.exists(dst):\n","#       shutil.copytree(f\"/content/rft-checkpoints/checkpoint-{step}\", dst)\n","#   except:\n","#     continue"],"metadata":{"id":"sk7vx5CHE7ud"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["== WITHOUT PEFT ==\n","\n","bs8 / grad_ckpt False => no OOM; 45 mins\n","\n","bs16 / grad_ckpt True => no OOM; 30 mins\n","\n","<pre>\n","rft_training_args = GRPOConfig(\n","    # Memory\n","    bf16=True,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=0,\n","    num_generations=4,\n","    gradient_checkpointing=True,\n","    max_prompt_length=256,\n","    max_completion_length=512,\n","    gradient_accumulation_steps=4,\n","    # Throughput\n","    use_vllm=False,\n","    # vllm_mode=\"colocate\",  # single-gpu setting\n","    num_train_epochs = 1, # Set to 1 for a full training run\n","    max_steps = -1,\n","    dataloader_num_workers=8,\n","    dataloader_prefetch_factor=2,\n","    dataloader_pin_memory=True,\n","    dataloader_persistent_workers=True,\n","    # save_steps = 10000,\n","    # Logging\n","    output_dir=\"./rft-checkpoints\",\n","    report_to=\"none\",\n",")</pre>\n","\n","setting per_device_train_batch_size=24 => no OOM; 25 mins\n","\n","also setting gradient_accumulation_steps=2 => no OOM; 40 mins"],"metadata":{"id":"PV00c6Uh_jce"}},{"cell_type":"code","source":["shutil.copytree(\"/content/rft-checkpoints/checkpoint-5-n=1000\",\n","                \"/content/drive/MyDrive/cs224r/rft/qwen2-1.5b-checkpoint-5_n=500\")"],"metadata":{"id":"Ruzme3ZsHIw7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","if not os.path.exists('/content/sft_checkpoints'):\n","  shutil.copytree(\"/content/drive/MyDrive/cs224r/sft/countdown-joint/\", \"/content/sft_checkpoints\")"],"metadata":{"id":"dmxD6FpELFQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9vNJphRygyRm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Eval"],"metadata":{"id":"LU5j6PfHgyxs"}},{"cell_type":"code","source":["shutil.copytree(\"/content/drive/MyDrive/cs224r/rft/countdown-joint/v5/checkpoint-200\",\n","                \"/content/rft-checkpoints-v5/checkpoint-200\")"],"metadata":{"id":"Sqkg-VMj1wRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","import torch\n","\n","from functools import partial\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Qwen2ForCausalLM\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from transformers import DataCollatorWithPadding, logging\n","from tqdm import tqdm\n","\n","logging.set_verbosity_error()\n","\n","# model_ckpt = \"/content/local-sft-checkpoint\"\n","# model_ckpt = \"/content/rft-checkpoints/qwen2-0.5b-checkpoint-3093\"\n","# model_ckpt = \"/content/sft_checkpoints/checkpoint-250\"\n","# model_ckpt = \"/content/sft_checkpoints/qwen2-0.5b-checkpoint-11050\"\n","# model_ckpt = \"PRETRAINED_MODEL_NAME\"\n","\n","checkpoints = [\n","    # \"/content/local-sft-checkpoint\",\n","    \"/content/rft-checkpoints/checkpoint-25\",\n","    \"/content/rft-checkpoints/checkpoint-50\",\n","    \"/content/rft-checkpoints/checkpoint-100\",\n","    \"/content/rft-checkpoints/checkpoint-150\",\n","    \"/content/rft-checkpoints/checkpoint-200\",\n","    # \"/content/rft-checkpoints/checkpoint-250\",\n","    # \"/content/rft-checkpoints/checkpoint-300\",\n","    # \"/content/rft-checkpoints/checkpoint-350\",\n","    # \"/content/rft-checkpoints/checkpoint-400\",\n","]"],"metadata":{"id":"_tKbGG_AHbwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_return_sequences = 5\n","\n","sampling_kwargs = {\n","    # \"do_sample\": False,  # deterministic; argmax greedy\n","    \"do_sample\": True,\n","    \"top_k\": 20,\n","    \"top_p\": 0.8,\n","    \"temperature\": 0.3,\n","    \"repetition_penalty\": 1.1,\n","    \"num_return_sequences\": num_return_sequences,\n","    # \"bos_token_id\": 151643,\n","}\n","\n","def tokenize(example, tokenizer):\n","  return tokenizer(example[\"prompt\"], padding=True, padding_side=\"left\", return_tensors='pt', add_special_tokens=False)\n","\n","# === Inference loop ===\n","def get_completions(model, tokenizer, data, device='cuda', bs=64):\n","  completions = [[] for _ in range(num_return_sequences)]\n","  max_new_tokens = 1024\n","  # val_loader = DataLoader(processed_valid_dataset, batch_size=256)\n","  val_loader = DataLoader(processed_valid_dataset, batch_size=bs)\n","\n","  with torch.no_grad():\n","      for batch in tqdm(val_loader, position=0, leave=True):\n","          input_ids = batch[\"input_ids\"].to(device)\n","          attention_mask = batch[\"attention_mask\"].to(device)\n","\n","          with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n","              generated_ids = model.generate(\n","                  input_ids=input_ids, attention_mask=attention_mask,\n","                  max_new_tokens=max_new_tokens,\n","                  **sampling_kwargs,\n","                  pad_token_id=tokenizer.eos_token_id\n","              )  # (batch_size x num_return_sequences, max_length)\n","\n","              generated_ids = generated_ids.reshape(\n","                  input_ids.shape[0],  # true batch size; may be < bs if final\n","                  num_return_sequences,\n","                  generated_ids.shape[1],  # max tokens from this batch\n","              )\n","\n","          # Only keep the generated suffix\n","          for idx in range(num_return_sequences):\n","            for inp, gen in zip(input_ids, generated_ids[:, idx, :]):\n","                gen_text = tokenizer.decode(gen[len(inp):], skip_special_tokens=True)\n","                completions[idx].append(gen_text)\n","  return completions"],"metadata":{"id":"5ryEkOekDQ-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_to_evaluate = valid_dataset\n","processed_valid_dataset = dataset_to_evaluate.map(partial(tokenize, tokenizer=tokenizer), batched=True)\n","processed_valid_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])"],"metadata":{"id":"yXhr6OoIDY_X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion_collection = []\n","from peft import AutoPeftModelForCausalLM\n","for model_ckpt in checkpoints:\n","  gc.collect()\n","  model = AutoModelForCausalLM.from_pretrained(model_ckpt,\n","                                               torch_dtype=\"auto\",  # bfloat16\n","                                               device_map=\"auto\");\n","  model.config.use_cache = True\n","  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","  model = torch.compile(model.to(device))\n","  model.eval()\n","\n","  completions_list = get_completions(model, tokenizer, processed_valid_dataset)\n","\n","  if DATASET_TYPE == \"MATH\":\n","    reward_floats = [reward_accuracy(prompts=None, completions=completions, verification_info=valid_dataset['verification_info']) for completions in completions_list]\n","    flat_rewards = [it for coll in reward_floats for it in coll]\n","    print(f\"{model_ckpt} accuracy: {sum(flat_rewards) / len(flat_rewards) * 100}\")\n","  elif DATASET_TYPE == \"COUNTDOWN\":\n","    reward_floats = [formula_match_v3(prompts=dataset_to_evaluate[\"prompt\"], completions=completions) for completions in completions_list]\n","    flat_rewards = [it for coll in reward_floats for it in coll]\n","    print(f\"{model_ckpt} accuracy: {sum(flat_rewards) / len(flat_rewards) * 100}\")\n","\n","  completion_collection.append(completions_list)"],"metadata":{"id":"UByF0DqBEPRP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion_collection[0][0][1]"],"metadata":{"id":"AsJpz-OMLJNy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion_collection[1][1]"],"metadata":{"id":"aVRl6kR-LTH4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion_collection[2][1]"],"metadata":{"id":"g7uKNXgfLhAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion_collection[3][1]"],"metadata":{"id":"9kpSNn1eevYN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion_collection[4][1]"],"metadata":{"id":"MXIgw1gQhmBA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","with open(\"/content/drive/MyDrive/cs224r/completions/rft-v31.json\", \"w\") as f:\n","  json.dump({\"completions\": completion_collection}, f)"],"metadata":{"id":"HpirpECW6gJ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def tokenize(example):\n","#   return tokenizer(example[\"prompt\"], padding=\"longest\", truncation=True, return_tensors='pt')\n","\n","# processed_valid_dataset = valid_dataset.map(tokenize, batched=True)\n","# processed_valid_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])"],"metadata":{"id":"ZbGL3nfNrwXC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # === Save completions ===\n","# if not os.path.exists(\"rft_completions.txt\"):\n","#   with open(\"rft_completions.txt\", \"w\", encoding=\"utf-8\") as f:\n","#       for line in completions:\n","#           f.write(line.strip() + \"\\n\")"],"metadata":{"id":"-lLwzhWd4TL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# if DATASET_TYPE == \"MATH\":\n","#   rewards = reward_accuracy(prompts=None, completions=completions, verification_info=valid_dataset['verification_info'])\n","#   print(f\"Accuracy: {sum(rewards) / len(rewards) * 100}\")\n","# elif DATASET_TYPE == \"COUNTDOWN\":\n","#   rewards = formula_match_v3(prompts=valid_dataset[\"prompt\"], completions=completions)\n","#   print(f\"Accuracy: {sum(rewards) / len(rewards) * 100}\")"],"metadata":{"id":"5KPsWAYs4Vzg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rewards_v2 = formula_match_v2(prompts=valid_dataset[\"prompt\"], completions=completions)\n","# rewards_v3 = formula_match_v3(prompts=valid_dataset[\"prompt\"], completions=completions)\n","\n","# for p, c, r2, r3 in zip(valid_dataset[\"prompt\"], completions, rewards_v2, rewards_v3):\n","#   if r2 != r3:\n","#     print(f\"PROMPT: {p}\\n\\nCOMPLETION: {c}\")"],"metadata":{"id":"hE-Q5IrJeWTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import output\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"],"metadata":{"id":"YGsqpTcP2ciJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N = 1\n","completions[N], valid_dataset[N]"],"metadata":{"id":"ATwvQZwclcMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reward_accuracy(prompts=None, completions=[completions[5]], verification_info=valid_dataset['verification_info'][5:6])"],"metadata":{"id":"GnCenlLtxKxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_dataset[5]"],"metadata":{"id":"Y2ziVvuX4r7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_dataset[9]['prompt'], valid_dataset[9]['verification_info']"],"metadata":{"id":"tvR2vdwGDyLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"W1CEyqdVD5KE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"40-towkInmhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GkvT1SednmpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7vNtRY74nm3u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zUtvWn7Enm9V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I72P7uJinnCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# {'top_k': 20, 'top_p': 0.8, 'repetition_penalty': 1.1, 'bos_token_id': 151643}\n","\n","peft_config = LoraConfig(\n","  r=8,\n","  lora_alpha=32,\n","  lora_dropout=0.1,\n","  bias=\"none\",\n","  task_type=\"CAUSAL_LM\",\n",")\n","\n","rft_training_args = GRPOConfig(\n","    # Memory\n","    bf16=True,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=0,\n","    num_generations=4,\n","    learning_rate=5e-7,\n","    gradient_checkpointing=True,\n","    gradient_checkpointing_kwargs={\"use_reentrant\": False},  # it sets use_cache=False anyways, but to be explicit...\n","    max_prompt_length=256,\n","    max_completion_length=1024,\n","    gradient_accumulation_steps=1,\n","    # Throughput\n","    use_vllm=False,\n","    # vllm_mode=\"colocate\",  # single-gpu setting\n","    num_train_epochs = 1, # Set to 1 for a full training run\n","    max_steps = -1,\n","    dataloader_num_workers=8,\n","    dataloader_prefetch_factor=2,\n","    dataloader_pin_memory=True,\n","    dataloader_persistent_workers=True,\n","    # Logging\n","    output_dir=\"./rft-checkpoints\",\n","    save_strategy=\"steps\",\n","    save_steps=50,\n","    # save_total_limit=2,\n","    logging_steps=1,\n","    report_to=\"none\",\n","    # Training\n","    reward_weights=[1.0, 0.1],\n","    beta=0.001,\n",")\n","\n","rft_trainer = HappyGRPOTrainer(\n","    \"/content/local-sft-checkpoint\",\n","    # reward_funcs=[reward_accuracy, len_penalty],  # MATH\n","    reward_funcs=[formula_match_v3, format_reward],\n","    args=rft_training_args,\n","    train_dataset=rft_train_dataset,\n","    callbacks=[metric_file_logger],\n","    peft_config=peft_config,\n",")"],"metadata":{"id":"zXf6rMJGnnHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rft_trainer.load"],"metadata":{"id":"SuvKSFPwnokJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Automatically disconnect and shut down the Colab runtime\n","import os\n","from google.colab import runtime\n","\n","# Option 1: Using the Colab `runtime` module (cleanest method)\n","runtime.unassign()\n","\n","# Option 2: Force shutdown (in case unassign doesn't work)\n","os._exit(0)"],"metadata":{"id":"BcG3XWKgt5hU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GozUT5lzt79t"},"execution_count":null,"outputs":[]}]}